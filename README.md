# Numerical Solutions for Boundary Value Problems:

## Introduction
Boundary Value Problems (BVPs) are essential in mathematical modelling across various fields. This report demonstrates numerical solutions to BVPs using Python, including error analysis, matrix formulation, and implementation of Newton's method for nonlinear problems. The report is structured to address all tasks provided, including solving linear and nonlinear BVPs and analyzing convergence rates.  

This project has the following tasks:  
1. Generate uniformly spaced points in the interval [a, b] with N interior points,
2. Use finite difference methods (forward, backward, central and extrapolated central) to approximate first-order solutions,
3. Generate the tridiagonal matrix (M) and RHS vector (F) for solving the BVP u'' = f(x),
4. Approximate the solutions to the BVP u'' = f(x) and compare it with the exact solution,
5. Solve (k(x)u')' = f where u(0) = A and u(1) = B,
6. Solve a system of nonlinear equations using Newton's method, and
7. Solve (M(u)u')' = f where u(0) = A and u(1) = B using Newton's method.

### Task 1: Generate uniformly spaced points in the interval [a, b] with N interior points

### Comments on Task 1 results:
We chose an interval from -2 to 10 with 10 interior points. If we see the above results, we can verify that our grid includes -2 and 10, i.e., boundary values. Other than boundary values, there are 10 interior points, i.e., 12 points in total, including boundary points. Another thing we can verify is that these points are uniformly spaced. The difference between the two grid points in the mesh is the same.

### Task 2: Use finite difference methods (forward, backward, central and extrapolated central) to approximate first-order solutions

### Comments on Task 2 results:
We computed the sin(x) derivative at x = 1 by looping over the required values of h using vectorized arrays. We used four formulas to calculate and compare the derivative with the actual derivative. We noticed that the error decreases as we increase the value of h, and we can imply that as h approaches zero (0), the solution to the first-order differential equation becomes accurate. However, the error decay is the same for forward and backward difference methods. Still, it decays quicker if we use the central difference method and even quicker than the central difference if we use the extrapolated central difference method.

### Task 3: Generate the tridiagonal matrix (M) and RHS vector (F) for solving the BVP u'' = f(x)
#### Problem setup:
$$u'' = f(x), \quad u(0) = A, \quad u(1) = B$$  
Let't take a simple function $f(x) = 2x$ and boundary conditions as $A = 0$ and $B = 1$.  
For $N = 10$, the grid points are $x_j = \frac {j}{N + 1}$, where $j = 0, 1, 2,...,N$.  
The grid spacing is: $h = \frac {b - a}{N + 1} = \frac {1}{N + 1} = \frac {1}{11} \approx 0.09090909$  
The grid points will be: $x_0 = 0, x_1 = 0.09090909, x_2 = 0.18181818,...,x_10 = 1$  
The centered finite difference approximation for the second derivative $u''(x)$ at grid points $x_j$ is:
$$u''(x_j) \approx \frac {1}{h^2} (u_{j-1} - 2u_j + u_{j+1})$$  
For each interior grid point $j = 1, 2,...,N-1$, the equation becomes:  
$$\frac {1}{h^2} (u_{j-1} - 2u_j + u_{j+1}) = f(x_j)$$  
Since $f(x) = 2x$, we have:  
$$f(x_j) = 2x_j = 2. \frac {j}{N + 1}$$  
for $j = 1,2,...N-1$  
The system can be written in matrix form as $M.U = F$, where matrix M is an $ N \times N$ tridiagonal matrix with main diagonal: $\frac{-2}{h^2}$ and off-diagonal: $\frac {1}{h^2}$, wheras vector F is a vector of size N:  
$$F = 
\begin{bmatrix}
f(x_1) - \frac{A}{h^2} \\
f(x_2) \\
\vdots \\
f(x_{N-1}) \\
f(x_N) - \frac{B}{h^2}
\end{bmatrix}$$  
where $f(x_j) = 2x_j$. This gives:  
$$F = 
\begin{bmatrix}
\frac {2}{N + 1} \\
\frac {4}{N + 1} \\
\vdots \\
\frac {2N}{N + 1}
\end{bmatrix}$$  

### Comments on Task 3 results:
The above results for $N = 10$ show that the matrix M generated by the code is a $10 \times 10$ matrix. The primary and off-diagonals of the matrix are calculated correctly, and the given vector F is of size 10 with boundary conditions implemented in it, i.e., $A = 0$ and $B = 1$.

### Task 4: Approximate the solutions to the BVP u'' = f(x) and compare it with the exact solution
#### Analytical solution:
The differential equation is: $u'' = f(x) = 2x$  
Integrate $u'' = 2x$ once to find u':  
$$u' = \int 2x \, dx = x^2 + C_1$$  
where $C_1$ is a constant of integration.  
Integrate again to find u:  
$$u = \int (x^2 + C_1) dx = \frac {x^3 }{3} + C_1x + C_2$$  
where $C_2$ is another constant of integration.  
Now, let's apply the boundary conditions as: $u(0) = A = 0$ and $u(1) = B = 1$  
For $u(0) = 0$ substituting $x = 0$ and $u(0) = 0$ gives:  
$$0 = \frac {0^3}{3} + C_1 . 0 + C_2 \implies C_2 = 0$$  
For $u(1) = 1$ substituting $x = 1$ and $u(1) = 1$ gives:  
$$1 = \frac {1^3}{3} + C_1 . 1 + 0 \implies 1 = \frac {1}{3} + C_1$$  
Solving for $C_1$:  
$$C_1 = 1 - \frac {1}{3} = \frac {2}{3}$$  
Thus, the exact solution is:  
$$u(x) = \frac {x^3}{3} + \frac {2x}{3}$$

### Comments on Task 4 results:
From the above chart, we can observe two trends:  
1. Error reduces as the number of interior points (N) increases, and
2. Error ratio increases as the number of interior points N increases, representing the convergence of solving BVP using finite difference approximations.

### Task 5: Solve (k(x)u')' = f where u(0) = A and u(1) = B
#### Problem setup:
$$(k(x)u')' = f(x), \quad u(0) = A, \quad u(1) = B$$  
Let's take the given function $k(x) = 1 + x^2$, $f(x) = 0$ and boundary conditions as $A = 0$ and $B = 1$.
#### Analytical solution
Since $f(x) = 0$, the derivative of $k(x)u'$ is zero, implying:
$k(x) \frac {du}{dx} = C_1$, where $C_1$ is a constant.  
By substituting $k(x) = 1 + x^2$, we get:  
$$(1 + x^2) \frac {du}{dx} = C_1.$$  
Rearranging for $\frac {du}{dx}, gives:$  
$$\frac {du}{dx} = \frac {C_1}{1+x^2}$$  
Let's integrate $\frac {du}{dx}$ to find $u(x)$:  
$$u(x) = \int \frac {C_1}{1 + x^2} dx + C_2 = C_1\int \frac {1}{1 + x^2} dx + C_2$$  
And by substituting $\int \frac {1}{1 + x^2} dx = arctan(x)$, we get:  
$$u(x) = C_1 arctan(x) + C_2$$  
Let's apply boundary conditions as $A = 0$:  
$$0 = C_1 arctan(0) + C_2 \implies C_2 = 0$$  
And at $B = 1$:  
$1 = C_1 arctan(1)$,  where $arctan(1) = \frac {\pi}{4}$. Substituting it will give us: $C_1 = \frac {1}{\pi/4} = \frac {4}{\pi}$. So, the solution will be:  
$$u(x) = \frac {4}{\pi} arctan(x)$$

### Comments on Task 5 results:
From the above chart, we can observe two trends:  
1. Error reduces as the number of interior points (N) increases and
2. Error ratio increases as the number of interior points N increases, representing the convergence of solving BVP using finite difference approximations.

### Task 6: Solve a system of nonlinear equations using Newton's method
#### Problem setup:
$x^2 + y^2 = 9$ (Equation 1)  
$x^2 - 2y = 1$ (Equation 2)
#### Analytical solution:
From equation 2 substitute $x^2 = 2y + 1$ in equation 1:  
$$(2y + 1) + y^2 = 9$$  
$$y^2 + 2y + 1 = 9 \implies y^2 + 2y - 8 = 0$$  
We can solve above equation using the quadratic formula:  
$$y = \frac{-2 \pm \sqrt{2^2 -4(1)(-8)}}{2(1)} = \frac{-2 \pm \sqrt{4 +32}}{2} = \frac{-2 \pm \sqrt{36}}{2} = \frac{-2 \pm 6}{2}$$  
From above equation, we can calculate possible values of y as: $y = \frac {-2 + 6}{2} = 2$ or $y = \frac {-2 -6}{2} = -4$  
We can substitute above values of y back to the expression $x^2 = 2y + 1$ to find values of x:  
If y = 2:  
$$x^2 = 2(2) + 1 = 5 \implies x = \pm \sqrt {5}$$  
If y = -4:  
$x^2 = 2(-4) + 1 = -8 + 1 = -7 \implies$ No real solution for $x$ at $y = -4$  
So, the exact solutions of this non-linear system would be: $(x, y) = (\sqrt{5}, 2)$ and $(x, y) = (-\sqrt{5}, 2)$

### Comments on Task 6 results:
We have executed the program to approximate the solution using Newton's method with two initial guesses:
1. $x = 1$, $y = 1$, and
2. $x = -1$, $y = 1$  

The system iterated it for a cap of 100 iterations and approximated the solutions we calculated analytically with a nominal difference due to rounding as we use a tolerance check of $1e^{-6}$.

### Task 7: Solve (M(u)u')' = f where u(0) = A and u(1) = B using Newton's method
#### Problem setup:
$(M(u)u')' = f, \quad u(0) = A, \quad u(1) = B$  
Let's take the given function $M(u) = 1 + u^2$, $f = 0$ and boundary conditions as $A = 0$ and $B = 1$.
#### Analytical solution:
$$(M(u)u')' = f$$  
where $M(u) = 1 + u^2$, $f = 0$, and the boundary conditions are $u(0) = A = 0$ and $u(1) = B = 1$.  

Since, $f = 0$, and $M(u) = 1 + u^2$, by substituting these values, we get:  
$$\frac {d}{dx}((1 + u^2)u') = 0$$  
Since the derivative of $(1 + u^2)u'$ is zero, it means that $(1 + u^2)u'$ is constant. So, we get below equation:  
$$(1 + u^2)u' = C$$  
Now, let's solve for $u'$:  
$$u' = \frac {C}{1 + u^2}$$  
Separating variables and integrating, gives:  
$$\int  (1 + u^2) du = \int C dx$$  
$\int (1 + u^2) du = u + \frac {u^3}{3}$ and $\int C dx = Cx + D$, so the equation becomes:  
$$u + \frac {u^3}{3} = Cx + D$$  
At $x = 0$, $u(0) = 0$, so:  
$$0 + \frac{0^3}{3} = C(0) + D \implies D = 0$$  
At $x = 1$, $u(1) = 1$, so:  
$$1 + \frac{1^3}{3} = C (1) + 0 \implies C = \frac {4}{3}$$  
So, the solution will be:  
$$u + \frac {u^3}{3} = \frac {4}{3}x$$
#### Residual function (M):
The residual funciton $G$ is defined such that $G_i=0$ for $i = 1,2,...,m$. The $i$-th component of G is:  
$$G_i = \frac {1}{h^2} [M(u_{i+1/2})(u_{i+1}-u_i) - M(u_{i-1/2})(u_i - u_{i-1})]$$
$$G_i = \frac {1}{h^2} [M(\frac {u_{i+1}+u_i}{2})(u_{i+1}-u_i) - M(\frac {u_i+u_{i-1}}{2})(u_i - u_{i-1})]$$
#### Jacobian matrix (J):
The Jacobian matrix $J$ is the matrix of partial derivatives of G with respect to u. The $(i, j)$-th entry of $J$ is:  
$$J_{ij}=\frac {\delta G_i}{\delta u_j}$$
Main diagonal at $j=1$ is given by:
$$\frac {\delta G_i}{\delta u_i} = \frac {1}{h^2}[M'(\frac {u_{i+1}+u_i}{2}). \frac {1}{2}(u_{i+1}-u_i)-M(\frac {u_{i+1}+u_i}{2})-M'(\frac {u_i + u_{i-1}}{2}).\frac {1}{2}(u_i - u_{i-1})-M(\frac {u_i + u_{i-1}}{2})]$$
Sub-diagonal at $j=i-1$ is given by:
$$\frac {\delta G_i}{\delta u_{i-1}} = -\frac {1}{h^2}[M'(\frac {u_i + u_{i-1}}{2}).\frac {1}{2}(u_i - u_{i-1})+M(\frac {u_i + u_{i-1}}{2})]$$
Super-diagonal at $j=i+1$ is given by:
$$\frac {\delta G_i}{\delta u_{i+1}} = \frac {1}{h^2}[M'(\frac {u_{i+1} + u_i}{2}).\frac {1}{2}(u_{i+1} - u_i)+M(\frac {u_{i+1} + u_i}{2})]$$
#### Solving the system:
We can use Newton's method to solve this nonlinear system $G(u) = 0$. At each iteration, we will solve the system as:  
$$J(u^{(k)}\delta^{(k)})=-G(u^{(k)})$$
After solving, we will update the solution as:  
$$u^{(k+1)} = u^{(k)}+\delta^{(k)}$$

### Comments on Task 7 results:
The chart in Figure 3 compares numerical and exact solutions for a nonlinear boundary value problem (BVP) as defined in the task introduction section. The numerical solutions were computed using Newton's method on a uniform grid, and its accuracy was assessed against the exact solution. From the plot in Figure 3, we can see that the approximated solution using Newton's method converges to the exact solution as the grid points are refined, i.e., the Exact and approximate solution should be the same if h becomes zero. This concept holds in the above solution.  

To further assess its convergence, we took a list of different grids as $N = 10, 20, 40, 80, 160$, and we computed the exact solution and approximate solution on these grids. Then, we computed the error between the exact and approximate solution and plotted the norm of error in the log scale in Figure 4. The plot in Figure 4 shows that the error value keeps decreasing as we increase the number of interior grid points.

## Conclusion
This study establishes the significance of finite difference and Newton’s methods in solving boundary value problems (BVPs) for linear and nonlinear equations. The numerical solutions fetched closely approximated the exact solutions, with central and extrapolated central difference schemes providing higher accuracy than forward and backward differences. The construction of the tridiagonal matrix and right-hand side vector played a crucial role in efficiently solving the discretized BVP.  

Newton’s method proved a reliable iterative approach for nonlinear equations, converging efficiently under appropriate initial guesses. Further, the choice of grid type significantly influenced the solution accuracy; the exponential grid provides better resolution in regions with steep gradients, outperforming the uniform grid in capturing rapid changes in the solution.  

Overall, the results highlight the essence of selecting appropriate numerical methods and grid structures for solving differential equations. Future work could explore adaptive grid refinement techniques or alternative iterative solvers to further improve accuracy and computational efficiency.

## References
1. LeVeque, R. J. (2005). *Finite Difference Methods for Differential Equations*. University of Washington.